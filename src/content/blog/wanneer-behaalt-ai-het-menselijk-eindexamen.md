---
title: "Wanneer behaalt AI het menselijk eindexamen?"
date: "2026-02-07"
tag: "Onderzoek"
excerpt: "Met scores van 2,7% en 4,1% zakken de beste AI-modellen genadeloos voor Humanity's Last Exam. De weg naar expert-niveau is langer dan gedacht."
status: "published"
---

<div className="font-mono text-xs md:text-sm leading-snug text-gray-800">
  <p className="mb-3">
    Jarenlang was de MMLU de gouden standaard, maar nu modellen daarop 90% scoren, is die lat te laag. Enter <a href="https://www.nature.com/articles/s41586-025-09962-4.pdf" target="_blank" rel="noopener noreferrer" class="text-[#8B1A3D] underline">Humanity's Last Exam (HLE)</a>: 2.500 expert-vragen die de harde waarheid blootleggen. Waar GPT-4o en Claude 3.5 Sonnet normaal uitblinken, scoren ze hier respectievelijk slechts 2,7% en 4,1%. Zelfs toekomstige modellen zoals GPT-5 komen in tests niet verder dan een magere 25,3%.
  </p>

  <p className="mb-3">
    Waarom deze <a href="https://theconversation.com/ai-is-failing-humanitys-last-exam-so-what-does-that-mean-for-machine-intelligence-274620" target="_blank" rel="noopener noreferrer" class="text-[#8B1A3D] underline">dramatische scores</a>? Omdat AI faalt waar patroonherkenning stopt en diep begrip begint. Drie pijnlijke voorbeelden uit de test:
  </p>

  <ul className="list-disc pl-5 mb-3 space-y-1">
    <li><strong>Visueel & Geschiedenis:</strong> Het vertalen van Palmyreense inscripties op een Romeinse grafsteen. Dit vereist visuele nuance én diepe historische context die AI mist.</li>
    <li><strong>Chemie & Ruimtelijk inzicht:</strong> Het analyseren van een pericyclische reactie (zoals bij endiandric acid). Modellen kennen de formules, maar 'zien' de ruimtelijke elektronenbeweging in het diagram niet.</li>
    <li><strong>Linguïstiek & Traditie:</strong> De exacte uitspraak van Hebreeuwse teksten volgens de Tiberiaanse traditie. Dit vereist hyper-specialistische kennis van middeleeuwse manuscripten die niet breed op internet staat om simpelweg te 'scrapen'.</li>
  </ul>
  
  <p className="mb-3">
    Erger nog is de arrogantie: modellen vertonen een enorme 'calibration error'. Ze bluffen zich met 80-90% zekerheid door vragen heen die ze faliekant fout hebben. Dit is een keiharde reality check: de weg van 'slimme chatbot' naar betrouwbare expert is nog lang. Onafhankelijke evaluatie is geen luxe, maar bittere noodzaak.
  </p>

  <p className="mt-4" style={{ color: "#2C3E50" }}>
    Gelukkig worden de grootste of gevaarlijke 'faal-momenten' van AI gedocumenteerd in de internationale <a href="https://incidentdatabase.ai/" target="_blank" rel="noopener noreferrer" class="text-[#8B1A3D] underline">AI Incident Database</a>, zodat we kunnen leren van fouten en deze in de toekomst voorkomen – net als in de luchtvaart. Kom je zelf een incident tegen? Meld het dan bij ons eigen <a href="#meldpunt" class="text-[#8B1A3D] underline">Meldpunt</a>.
  </p>
</div>
